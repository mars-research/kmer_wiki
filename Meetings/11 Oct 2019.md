# 11 Oct 2019

Created: Oct 10, 2019 9:06 PM
Created By: Harishankar Vishwanathan
Last Edited Time: Nov 17, 2019 11:45 PM

- Remaining questions
- Lock-free programming:
    - atomic operations, memory barriers, ABA
    - different from lock-less (no locks in code), lock free only means a multi-threaded program on a multi-core system won't get locked up due to deadlocks (other types: livelock, scheduling)
    - [https://preshing.com/20120612/an-introduction-to-lock-free-programming/](https://preshing.com/20120612/an-introduction-to-lock-free-programming/)

- Fast Forrward
    - available/ready made it very clear
    - how do they come up with such things? how do people think that something like this is even possible? Theory people/ systems people?

Other Questions

- Since the main idea in MCS locks is waiting on different cache lines, how can we ensure that two thread-local MCS lock nodes are on different cache lines? If the queue is `HeadNode->Thread1Node->Thread2Node`, the latter two could very well be placed in close locations in memory and be on the same cache line right?

Papers to send:

- Jellyfish
    - Community that builds histograms
- Lock free lists.

- Code
    - Why kthread, why in kernel?
    - Could it have been done without the intermediate huge array?

- Misc
    - monitor, keyboard
    - keys
    - courses matching, 2 courses
    - speak test
    - 

TODO

- fix seg_fault in main.c
- With batches seems to be performing worse.