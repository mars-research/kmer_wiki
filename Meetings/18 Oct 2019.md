# 18 Oct 2019

Created: Oct 23, 2019 2:28 AM
Created By: Harishankar Vishwanathan
Last Edited Time: Oct 23, 2019 2:28 AM

- node about batches:
there are 3 producuers and 3 consumers
so 3 queues.
producer 1 enqueues data for consumer 1, then consumer 2, then consumer 3
to do this, it enqueues data in batch_size amounts.
so enqeueu 16 packets for consumer 1 queue, then 16 for consumer 2, and so on
faster than doing 1 and moving on.
- run experiment:
batch 1, cycles per packet,
run it with batch 2, see how many cycles per packet
- think whether we can optimize transferring cache lines more
- understand why bqueue is faster than ff
read bqueue paper with the goal of understanding cache line bouncing reduction
- note:
anton does not touch data node after prefetching
touching simulates usage
for touching, need to store the node pointers in some array after dequeuing
- a node pointer may be 16 bytes, so 4 pointers may be prefetched into
a cache line on one prefetch instruction
-> ask anton about this.
- push code to git.
- Anton lectures on calling conventions